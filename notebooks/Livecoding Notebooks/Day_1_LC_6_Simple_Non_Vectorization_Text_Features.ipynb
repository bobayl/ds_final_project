{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ7rW1rZ6t-K"
   },
   "source": [
    "# Simple Non-Vectorization Text Features\n",
    "\n",
    "\n",
    "\n",
    "Since text cannot be directly utilized by any downstream machine learning or deep learning model (given these are mathematical functions at heart, we need to transform it into numeric or vectorized formats.\n",
    "\n",
    "In this tutorial, we will work towards extracting various features from text so as to use them for different NLP tasks. There are vectorization methods which we will cover in the next tutorial.\n",
    "\n",
    "In this tutorial we will focus on simple non-vectorized methodologies which will try and derive features from various properties of the text content. The idea is these features being numeric can be used by downstream machine learning models as necessary for downstream tasks which you will learn about in the next few modules.\n",
    "\n",
    "In this notebook, we will cover:\n",
    "- Count based hand-crafted features\n",
    "- Parts of Speech based features\n",
    "- Text Legibility features\n",
    "- Sentiment-based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKG8deo066It"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "BPVzv_J43rD4"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3gTJoX67BW-"
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "``sklearn`` provides a number of datasets for understanding and building NLP pipelines. In this notebook we will make use of **20-newsgroups** dataset. This notebook consists of a number of news articles classified under various categories.\n",
    "\n",
    "For the purposes of this notebook/tutorial we will only focus on the actual article _text_ only for the space-scientific articles category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kRAFaWP26-72"
   },
   "outputs": [],
   "source": [
    "cats = ['sci.space']\n",
    "news_group_data = fetch_20newsgroups(subset='train', categories=cats,remove=('headers', 'footers', 'quotes')).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fansbkv1-A69",
    "outputId": "0ff770bf-42f8-498d-aeaa-df660fa9ad2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    'article':news_group_data\n",
    "})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zciNKrXE_XqH",
    "outputId": "432a650e-ddc3-41d8-fc87-98754a9d29e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nAny lunar satellite needs fuel to do regular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nGlad to see Griffin is spending his time on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nIn spite of my great respect for the peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\nDidn't one of the early jet fighters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just got out of the Army. Go signal corps or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article\n",
       "0  \\nAny lunar satellite needs fuel to do regular...\n",
       "1  \\nGlad to see Griffin is spending his time on ...\n",
       "2  \\n\\n\\nIn spite of my great respect for the peo...\n",
       "3  \\n\\n\\n\\n\\nDidn't one of the early jet fighters...\n",
       "4  I just got out of the Army. Go signal corps or..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVKBefdr_hbn"
   },
   "source": [
    "How the first article looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "iSdZGKyM_dti",
    "outputId": "e5d35514-3deb-4de3-c03d-56c4e6ae510e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAny lunar satellite needs fuel to do regular orbit corrections, and when\\nits fuel runs out it will crash within months.  The orbits of the Apollo\\nmotherships changed noticeably during lunar missions lasting only a few\\ndays.  It is *possible* that there are stable orbits here and there --\\nthe Moon's gravitational field is poorly mapped -- but we know of none.\\n\\nPerturbations from Sun and Earth are relatively minor issues at low\\naltitudes.  The big problem is that the Moon's own gravitational field\\nis quite lumpy due to the irregular distribution of mass within the Moon.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lfke303Q7cvm"
   },
   "source": [
    "## Count Based Features\n",
    "\n",
    "Counting presence or absence of certain words/characters is a good proxy of the information contained in a sentence/corpus. In this section, we will prepare a list of various count based hand-crafted features such as:\n",
    "\n",
    "- **Word Count**: total number of words in the documents\n",
    "- **Character Count**: total number of characters in the documents\n",
    "- **Average Word Density**: average length of the words used in the documents\n",
    "- **Puncutation Count**: total number of punctuation marks in the documents\n",
    "- **Upper Case Count**: total number of upper count words in the documents\n",
    "- **Title Word Count**: total number of proper case (title) words in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Sgbjyn3M7vGw"
   },
   "outputs": [],
   "source": [
    "feature_col = 'article'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ohf_PxZF6-5c"
   },
   "outputs": [],
   "source": [
    "df['char_count'] = df[feature_col].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FSNmijMd8BAr"
   },
   "outputs": [],
   "source": [
    "df['word_count'] = df[feature_col].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qDlV1Mzg8A1g"
   },
   "outputs": [],
   "source": [
    "df['word_density'] = df['char_count'] / (df['word_count']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dFHUd1c58Arv"
   },
   "outputs": [],
   "source": [
    "df['punctuation_count'] = df[feature_col].apply(lambda x: len(\"\".join(a for a in x if a in string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "R3apI17O8GJd"
   },
   "outputs": [],
   "source": [
    "df['title_word_count'] = df[feature_col].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FzE-je8d8GvZ"
   },
   "outputs": [],
   "source": [
    "df['upper_case_word_count'] = df[feature_col].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sxkdhNcI6-2o",
    "outputId": "ec994c69-13c2-460e-d0a4-4d511e28aeff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nAny lunar satellite needs fuel to do regular...</td>\n",
       "      <td>575</td>\n",
       "      <td>97</td>\n",
       "      <td>5.867347</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nGlad to see Griffin is spending his time on ...</td>\n",
       "      <td>184</td>\n",
       "      <td>32</td>\n",
       "      <td>5.575758</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nIn spite of my great respect for the peo...</td>\n",
       "      <td>666</td>\n",
       "      <td>122</td>\n",
       "      <td>5.414634</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\nDidn't one of the early jet fighters...</td>\n",
       "      <td>262</td>\n",
       "      <td>46</td>\n",
       "      <td>5.574468</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just got out of the Army. Go signal corps or...</td>\n",
       "      <td>281</td>\n",
       "      <td>50</td>\n",
       "      <td>5.509804</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  char_count  word_count  \\\n",
       "0  \\nAny lunar satellite needs fuel to do regular...         575          97   \n",
       "1  \\nGlad to see Griffin is spending his time on ...         184          32   \n",
       "2  \\n\\n\\nIn spite of my great respect for the peo...         666         122   \n",
       "3  \\n\\n\\n\\n\\nDidn't one of the early jet fighters...         262          46   \n",
       "4  I just got out of the Army. Go signal corps or...         281          50   \n",
       "\n",
       "   word_density  punctuation_count  title_word_count  upper_case_word_count  \n",
       "0      5.867347                 14                 9                      0  \n",
       "1      5.575758                  2                 3                      0  \n",
       "2      5.414634                 15                13                      8  \n",
       "3      5.574468                 11                 5                      4  \n",
       "4      5.509804                  4                 7                      2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjyZ_5Pq8KXU"
   },
   "source": [
    "## Parts of Speech Features\n",
    "\n",
    "Count based features are easy to create and understand. Yet count based features do not make use of any linguistic constructs or contextual information. In week-1 we studied about _Parts of Speech Tagging_. POS tagging helps us capture different constructs of a sentence such as nouns, verbs, etc.\n",
    "\n",
    "In this section, we will prepare features based on POS tags, such as:\n",
    "\n",
    "- Noun Count\n",
    "- Verb Count\n",
    "- Adjective Count\n",
    "- Adverb Count\n",
    "- Pronoun Count\n",
    "\n",
    "[Reference](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BRqKb4u5_wxJ"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "re91V9M9_rBY",
    "outputId": "c14f036d-6538-453a-9bb5-eed249f4602b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/laurent/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/laurent/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2AeTcoyv6-ra"
   },
   "outputs": [],
   "source": [
    "import textblob\n",
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' :  ['RB','RBR','RBS','WRB']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1eFhWWTm8uSJ"
   },
   "outputs": [],
   "source": [
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "# note this may take some time to execute on larger corpora\n",
    "\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KguZTDtv84sP"
   },
   "outputs": [],
   "source": [
    "feature_col = 'article'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "c-s2RmMz8uNp"
   },
   "outputs": [],
   "source": [
    "df['noun_count'] = df[feature_col].apply(lambda x: check_pos_tag(x, 'noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "e7FVjFhW8uFt"
   },
   "outputs": [],
   "source": [
    "df['verb_count'] = df[feature_col].apply(lambda x: check_pos_tag(x, 'verb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "7uHYGFR49BWU"
   },
   "outputs": [],
   "source": [
    "df['adj_count'] = df[feature_col].apply(lambda x: check_pos_tag(x, 'adj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "apZB1ubu9CqC"
   },
   "outputs": [],
   "source": [
    "df['adv_count'] = df[feature_col].apply(lambda x: check_pos_tag(x, 'adv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FdvoTpbx9Dt_"
   },
   "outputs": [],
   "source": [
    "df['pron_count'] = df[feature_col].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fUG8NRXLBCha",
    "outputId": "9f08f82e-549d-42a2-ac02-2b96b462e991"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nAny lunar satellite needs fuel to do regular...</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nGlad to see Griffin is spending his time on ...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nIn spite of my great respect for the peo...</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\nDidn't one of the early jet fighters...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just got out of the Army. Go signal corps or...</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  noun_count  verb_count  \\\n",
       "0  \\nAny lunar satellite needs fuel to do regular...          28          13   \n",
       "1  \\nGlad to see Griffin is spending his time on ...           9           5   \n",
       "2  \\n\\n\\nIn spite of my great respect for the peo...          26          21   \n",
       "3  \\n\\n\\n\\n\\nDidn't one of the early jet fighters...          13           8   \n",
       "4  I just got out of the Army. Go signal corps or...          14           7   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \n",
       "0         16          8           4  \n",
       "1          2          2           2  \n",
       "2         13          7          14  \n",
       "3          2          6           2  \n",
       "4          6          4           3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['article','noun_count','verb_count','adj_count','adv_count','pron_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJgFUC3LDtAO"
   },
   "source": [
    "# Text Legibility Features\n",
    "\n",
    "There are a wide variety of text legibility tests which can be leveraged to extract various statistics from text data which can be used as a measure of ease of understanding, readability and complexity.\n",
    "\n",
    "The [`textstat`](https://pypi.org/project/textstat/) package provides a wide variety of such tests which can be leveraged to extract text legibility features.\n",
    "\n",
    "We will cover a few of the essential ones here including:\n",
    "\n",
    "- Syllable Counts\n",
    "- Sentence Counts\n",
    "- Flesch Reading Ease Score\n",
    "- Automated Readability Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDbnMpsXBDyZ",
    "outputId": "f04bfd42-3797-480e-8976-06418b672143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in /Users/laurent/anaconda3/envs/tf_metal_gpu/lib/python3.10/site-packages (0.7.3)\n",
      "Requirement already satisfied: pyphen in /Users/laurent/anaconda3/envs/tf_metal_gpu/lib/python3.10/site-packages (from textstat) (0.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Sxa64hR5BSZd"
   },
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqqU0-7PEc2r"
   },
   "source": [
    "## Syllable Count\n",
    "\n",
    "Returns the number of syllables present in the given text document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fro_Q8SwBQu3"
   },
   "outputs": [],
   "source": [
    "df['syllable_count'] = [textstat.syllable_count(doc)\n",
    "                          for doc in df[feature_col].values]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVDJJHPREjP7"
   },
   "source": [
    "## Sentence Count\n",
    "\n",
    "Returns the number of sentences present in the given text document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Nb52GlnuBYVV"
   },
   "outputs": [],
   "source": [
    "df['sentence_count'] = [textstat.sentence_count(doc)\n",
    "                          for doc in df[feature_col].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKo7-_lzEq8M"
   },
   "source": [
    "## Flesch Reading Ease Score\n",
    "\n",
    "In the Flesch reading-ease test, higher scores indicate material that is easier to read; lower numbers mark passages that are more difficult to read. The formula for the Flesch reading-ease score (FRES) test and the score interpretations are showcased as follows based on [Wikipedia](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch_reading_ease)\n",
    "\n",
    "![](https://i.imgur.com/YxgbUpv.png)\n",
    "\n",
    "While the maximum score is 121.22, there is no limit on how low the score can be. A negative score is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YsJI02KSBq9O"
   },
   "outputs": [],
   "source": [
    "df['flesch_reading_ease_score'] = [textstat.flesch_reading_ease(doc)\n",
    "                                      for doc in df[feature_col].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNmRQl9AGh-B"
   },
   "source": [
    "## Automated Readability Index\n",
    "\n",
    "The automated readability index (ARI) is a readability test for English texts, designed to gauge the understandability of a text.\n",
    "\n",
    "Like the Flesch–Kincaid grade level, Gunning fog index etc., it produces an approximate representation of the US grade level needed to comprehend the text.\n",
    "\n",
    "The complete formula for computing the index and interpretation is depicted as follows thanks to [Wikipedia](https://en.wikipedia.org/wiki/Automated_readability_index)\n",
    "\n",
    "![](https://i.imgur.com/2ohzUok.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "u0LKmYckCTjN"
   },
   "outputs": [],
   "source": [
    "df['automated_readability_index'] = [textstat.automated_readability_index(doc)\n",
    "                                      for doc in df[feature_col].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DpvOHYV4CT6B",
    "outputId": "d5d20258-5ee3-455a-e4b5-dc8e2e41e3e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>flesch_reading_ease_score</th>\n",
       "      <th>automated_readability_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nAny lunar satellite needs fuel to do regular...</td>\n",
       "      <td>147</td>\n",
       "      <td>5</td>\n",
       "      <td>60.65</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nGlad to see Griffin is spending his time on ...</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>63.70</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nIn spite of my great respect for the peo...</td>\n",
       "      <td>163</td>\n",
       "      <td>7</td>\n",
       "      <td>79.19</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\nDidn't one of the early jet fighters...</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>87.52</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just got out of the Army. Go signal corps or...</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>71.44</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  syllable_count  \\\n",
       "0  \\nAny lunar satellite needs fuel to do regular...             147   \n",
       "1  \\nGlad to see Griffin is spending his time on ...              47   \n",
       "2  \\n\\n\\nIn spite of my great respect for the peo...             163   \n",
       "3  \\n\\n\\n\\n\\nDidn't one of the early jet fighters...              60   \n",
       "4  I just got out of the Army. Go signal corps or...              68   \n",
       "\n",
       "   sentence_count  flesch_reading_ease_score  automated_readability_index  \n",
       "0               5                      60.65                         11.6  \n",
       "1               2                      63.70                          8.8  \n",
       "2               7                      79.19                          8.0  \n",
       "3               5                      87.52                          4.3  \n",
       "4               3                      71.44                          8.1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['article', 'syllable_count', 'sentence_count', 'flesch_reading_ease_score',\n",
    "    'automated_readability_index']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJULhmJNHbPK"
   },
   "source": [
    "## Sentiment Based Features\n",
    "\n",
    "If you are dealing with subjective and opinionated text where people often express stong emotions, feelings.\n",
    "\n",
    "This might make it a classic case where the text documents  are a good candidate for extracting sentiment as a feature.\n",
    "\n",
    "TextBlob is an excellent open-source library for performing NLP tasks with ease, including sentiment analysis. It also an a sentiment lexicon (in the form of an XML file) which it leverages to give both polarity and subjectivity scores.\n",
    "\n",
    "- The polarity score is a float within the range [-1.0, 1.0].\n",
    "- The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "Perhaps this could be used for getting some new features? Let's look at some basic examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKjtNXxpDJaz",
    "outputId": "68ff9d6d-133d-4071-f8f9-ab959eeb20a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.7500000000000001, subjectivity=0.9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.TextBlob('This is an AMAZING pair of Jeans!').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KP9rWuLEJLHG",
    "outputId": "93467a58-1051-49b6-8b0e-8f5e4eeef4cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.95, subjectivity=0.85)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.TextBlob('I really hated this UGLY T-shirt!!').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL-e7hoqJPW_"
   },
   "source": [
    "Remember this is unsupervised, lexicon-based sentiment analysis where we don't have any pre-labeled data saying which article might have a positive or negative sentiment. We use the lexicon to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "g5f3fCnLJMrI"
   },
   "outputs": [],
   "source": [
    "df_snt_obj = df[feature_col].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "df['Polarity'] = [obj.polarity for obj in df_snt_obj.values]\n",
    "df['Subjectivity'] = [obj.subjectivity for obj in df_snt_obj.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4tQQ1248Jh0P",
    "outputId": "544aa6ce-8509-4723-a563-0b7a688e1373"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nAny lunar satellite needs fuel to do regular...</td>\n",
       "      <td>-0.015909</td>\n",
       "      <td>0.431993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nGlad to see Griffin is spending his time on ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nIn spite of my great respect for the peo...</td>\n",
       "      <td>-0.008532</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\nDidn't one of the early jet fighters...</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just got out of the Army. Go signal corps or...</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  Polarity  Subjectivity\n",
       "0  \\nAny lunar satellite needs fuel to do regular... -0.015909      0.431993\n",
       "1  \\nGlad to see Griffin is spending his time on ...  0.200000      0.600000\n",
       "2  \\n\\n\\nIn spite of my great respect for the peo... -0.008532      0.535714\n",
       "3  \\n\\n\\n\\n\\nDidn't one of the early jet fighters...  0.130208      0.244444\n",
       "4  I just got out of the Army. Go signal corps or...  0.210000      0.580000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['article', 'Polarity', 'Subjectivity']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnb7XlypKG71"
   },
   "source": [
    "Let's look at the article text with the highest negative sentiment and its other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXTajOUfJuXp",
    "outputId": "ae9d750d-c623-4e92-b9a7-0348b409b778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Polarity'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLj-X-6KJxTN",
    "outputId": "6f6a380a-7bce-4ac9-c1ef-9ca9340d4014"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article                        \\nI assume, then, that someone at Thiokol put ...\n",
       "char_count                                                                   225\n",
       "word_count                                                                    42\n",
       "word_density                                                            5.232558\n",
       "punctuation_count                                                              7\n",
       "title_word_count                                                               2\n",
       "upper_case_word_count                                                          2\n",
       "noun_count                                                                     9\n",
       "verb_count                                                                     9\n",
       "adj_count                                                                      1\n",
       "adv_count                                                                      3\n",
       "pron_count                                                                     3\n",
       "syllable_count                                                                54\n",
       "sentence_count                                                                 1\n",
       "flesch_reading_ease_score                                                  54.23\n",
       "automated_readability_index                                                 20.1\n",
       "Polarity                                                                    -0.7\n",
       "Subjectivity                                                            0.666667\n",
       "Name: 226, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "hgHRzpUJJ39s",
    "outputId": "b89554bb-8737-4080-ed70-8def9af2bee0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI assume, then, that someone at Thiokol put on their \"manager\\'s hat\" and said\\nthat pissing off the customer by delaying shipment of the SRB to look inside\\nit was a bad idea, regardless of where that tool might have ended up.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[226]['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
